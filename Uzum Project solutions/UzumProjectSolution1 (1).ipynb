{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae74efb2-4d7d-4199-b370-8bf21fed548e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#step 1 Loading + Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1964d5-1ee5-40fe-bf61-f67cce893e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>cause</th>\n",
       "      <th>comment</th>\n",
       "      <th>date_created_x</th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>purchase_price</th>\n",
       "      <th>review_text</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_created_y</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_title</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69138</td>\n",
       "      <td>6a1a7601fac958ee967c73fe19315db8f6cdc3f1cd8370...</td>\n",
       "      <td>DEFECTED</td>\n",
       "      <td>брак</td>\n",
       "      <td>2023-01-02 05:37:33.846</td>\n",
       "      <td>588140</td>\n",
       "      <td>b4465ede5691891836ccc432bb8c49e1537b1d0a74f721...</td>\n",
       "      <td>106000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>a073f12ea698964c47150c2b8f5fa937c639bdc54e223a...</td>\n",
       "      <td>Yogʻochni kuydirib naqsh solish, yogʻochdan qi...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69148</td>\n",
       "      <td>7cab221310edf5f3c75fc38259bcb7640d080b4b05d5bb...</td>\n",
       "      <td>PHOTO_MISMATCH</td>\n",
       "      <td>думала больше</td>\n",
       "      <td>2023-01-02 05:44:34.432</td>\n",
       "      <td>773695</td>\n",
       "      <td>9bf74458174dd9c039ee6317fd48b356e8fc146f23c60b...</td>\n",
       "      <td>23000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>593db514530578cd1b1c5b0986d8fd36543975cfa0d038...</td>\n",
       "      <td>Кошельки</td>\n",
       "      <td>b'{\"ru\":\"\\\\u041a\\\\u043e\\\\u0448\\\\u0435\\\\u043b\\\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69154</td>\n",
       "      <td>728611508a21a9214f2c8cc076d21e30046ec5c59bf359...</td>\n",
       "      <td>DEFECTED</td>\n",
       "      <td>брак</td>\n",
       "      <td>2023-01-02 05:45:31.277</td>\n",
       "      <td>695067</td>\n",
       "      <td>0a185871d03ee346b71b657d3fbaebfc35823fec2861f7...</td>\n",
       "      <td>390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>27a827d1bd879e7e131791bc9b7e8df227a9082fac9f2b...</td>\n",
       "      <td>Аксессуары для маникюра и педикюра</td>\n",
       "      <td>b'{\"ru\":\"\\\\u041c\\\\u043d\\\\u043e\\\\u0433\\\\u043e\\\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69161</td>\n",
       "      <td>f4f4031321f9b7cf1175fc6d363769297334ddd76aa2eb...</td>\n",
       "      <td>WRONG_ITEM</td>\n",
       "      <td>не тот товар</td>\n",
       "      <td>2023-01-02 05:57:35.652</td>\n",
       "      <td>635687</td>\n",
       "      <td>1123ce2b71eb64c572e6de0e14a723c17a55f67748327d...</td>\n",
       "      <td>71000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>e56fd4d103751c5d8ce2b26297eee56752470b543b6624...</td>\n",
       "      <td>Лонгсливы</td>\n",
       "      <td>b'{\"ru\":\"\\\\u043b\\\\u043e\\\\u043d\\\\u0433\\\\u0441\\\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69165</td>\n",
       "      <td>c8f3f349fa927aae5fc954c5268b578b9916a908bb1f8a...</td>\n",
       "      <td>DEFECTED</td>\n",
       "      <td>не включается и не работает</td>\n",
       "      <td>2023-01-02 05:59:34.447</td>\n",
       "      <td>764986</td>\n",
       "      <td>95cd02979c6f97dc58590f7c0e6c421d7c3db2b9e7212b...</td>\n",
       "      <td>84000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>93f606bd517c88c296b17fe207ea50ce5019e0daa47ab2...</td>\n",
       "      <td>Машинки для удаления катышек</td>\n",
       "      <td>b'{\"ru\":\"\\\\u041c\\\\u0430\\\\u0448\\\\u0438\\\\u043d\\\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                         product_id           cause  \\\n",
       "0  69138  6a1a7601fac958ee967c73fe19315db8f6cdc3f1cd8370...        DEFECTED   \n",
       "1  69148  7cab221310edf5f3c75fc38259bcb7640d080b4b05d5bb...  PHOTO_MISMATCH   \n",
       "2  69154  728611508a21a9214f2c8cc076d21e30046ec5c59bf359...        DEFECTED   \n",
       "3  69161  f4f4031321f9b7cf1175fc6d363769297334ddd76aa2eb...      WRONG_ITEM   \n",
       "4  69165  c8f3f349fa927aae5fc954c5268b578b9916a908bb1f8a...        DEFECTED   \n",
       "\n",
       "                       comment          date_created_x  order_item_id  \\\n",
       "0                         брак 2023-01-02 05:37:33.846         588140   \n",
       "1               думала больше  2023-01-02 05:44:34.432         773695   \n",
       "2                         брак 2023-01-02 05:45:31.277         695067   \n",
       "3                 не тот товар 2023-01-02 05:57:35.652         635687   \n",
       "4  не включается и не работает 2023-01-02 05:59:34.447         764986   \n",
       "\n",
       "                                         customer_id  purchase_price  \\\n",
       "0  b4465ede5691891836ccc432bb8c49e1537b1d0a74f721...          106000   \n",
       "1  9bf74458174dd9c039ee6317fd48b356e8fc146f23c60b...           23000   \n",
       "2  0a185871d03ee346b71b657d3fbaebfc35823fec2861f7...          390000   \n",
       "3  1123ce2b71eb64c572e6de0e14a723c17a55f67748327d...           71000   \n",
       "4  95cd02979c6f97dc58590f7c0e6c421d7c3db2b9e7212b...           84000   \n",
       "\n",
       "  review_text shop_id  rating date_created_y  \\\n",
       "0         NaN     NaN     NaN            NaT   \n",
       "1         NaN     NaN     NaN            NaT   \n",
       "2         NaN     NaN     NaN            NaT   \n",
       "3         NaN     NaN     NaN            NaT   \n",
       "4         NaN     NaN     NaN            NaT   \n",
       "\n",
       "                                         category_id  \\\n",
       "0  a073f12ea698964c47150c2b8f5fa937c639bdc54e223a...   \n",
       "1  593db514530578cd1b1c5b0986d8fd36543975cfa0d038...   \n",
       "2  27a827d1bd879e7e131791bc9b7e8df227a9082fac9f2b...   \n",
       "3  e56fd4d103751c5d8ce2b26297eee56752470b543b6624...   \n",
       "4  93f606bd517c88c296b17fe207ea50ce5019e0daa47ab2...   \n",
       "\n",
       "                                      category_title  \\\n",
       "0  Yogʻochni kuydirib naqsh solish, yogʻochdan qi...   \n",
       "1                                           Кошельки   \n",
       "2                 Аксессуары для маникюра и педикюра   \n",
       "3                                          Лонгсливы   \n",
       "4                       Машинки для удаления катышек   \n",
       "\n",
       "                                 product_description  \n",
       "0                                               None  \n",
       "1  b'{\"ru\":\"\\\\u041a\\\\u043e\\\\u0448\\\\u0435\\\\u043b\\\\...  \n",
       "2  b'{\"ru\":\"\\\\u041c\\\\u043d\\\\u043e\\\\u0433\\\\u043e\\\\...  \n",
       "3  b'{\"ru\":\"\\\\u043b\\\\u043e\\\\u043d\\\\u0433\\\\u0441\\\\...  \n",
       "4  b'{\"ru\":\"\\\\u041c\\\\u0430\\\\u0448\\\\u0438\\\\u043d\\\\...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df_return_reasons = pd.read_parquet('return_reasons.parquet')\n",
    "df_reviews = pd.read_parquet('reviews.parquet')\n",
    "df_returns = pd.read_parquet('returns.parquet')\n",
    "df_products = pd.read_parquet('products.parquet')\n",
    "df_test = pd.read_parquet('test.parquet')\n",
    "\n",
    "# Merge the datasets\n",
    "df = pd.merge(df_returns, df_reviews, on=['order_item_id', 'product_id', 'customer_id'], how='left')\n",
    "df.head()\n",
    "df = pd.merge(df, df_products, on='product_id', how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3b95c0-7ff4-49a9-9f18-bc5751b8256b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#step 2 Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609927f2-6103-4335-844c-95eed14d79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 text feature extractions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5642de-9bc1-42cb-a001-56489bc19340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    \"\"\"\n",
    "    Calculate the sentiment score for the given text using VADER.\n",
    "    If the text is in Russian, translate it to English before performing sentiment analysis.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Check if the text is in Russian\n",
    "        if any(char in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя' for char in text.lower()):\n",
    "            # Translate Russian text to English using the transformers library\n",
    "            model_name = 'Helsinki-NLP/opus-mt-ru-en'\n",
    "            tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "            model = MarianMTModel.from_pretrained(model_name)\n",
    "            \n",
    "            input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "            output_ids = model.generate(input_ids, max_length=512, num_beams=4, early_stopping=True)[0]\n",
    "            en_text = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "        else:\n",
    "            en_text = text\n",
    "\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        sentiment_dict = analyzer.polarity_scores(en_text)\n",
    "        return sentiment_dict['compound']\n",
    "    else:\n",
    "        return 0  # or any other default value you want to use for non-string inputs\n",
    "\n",
    "# Feature engineering\n",
    "df['review_length'] = df['review_text'].str.len()\n",
    "df['sentiment_score'] = df['review_text'].apply(get_sentiment_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff5790-6004-4a4d-a9a4-5f7a22d14950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class BERTEmbeddingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        bert_embeddings = []\n",
    "        for text in X['review_text']:\n",
    "            if isinstance(text, str):\n",
    "                # Tokenize the text\n",
    "                input_ids = torch.tensor([self.tokenizer.encode(text, add_special_tokens=True, max_length=512, truncation=True)])\n",
    "                \n",
    "                # Get the BERT embeddings\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(input_ids)\n",
    "                    embeddings = outputs[0][0, 0, :].numpy()\n",
    "                bert_embeddings.append(embeddings)\n",
    "            else:\n",
    "                bert_embeddings.append(np.zeros(768))  # Return a default vector for non-string inputs\n",
    "        return np.array(bert_embeddings)\n",
    "\n",
    "# Create the BERT embedding transformer\n",
    "bert_transformer = BERTEmbeddingTransformer(tokenizer, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1331ad-cb6f-4c1e-86ec-7b5b35a8a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4 Model selection and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec6cfc-c864-44f6-94ef-6d630e1c14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_num = df[['review_length', 'sentiment_score', 'purchase_price', 'rating']]\n",
    "X_text = df['review_text']\n",
    "X_bert = bert_transformer.transform(df)\n",
    "X = np.hstack((X_num, X_text, X_bert))\n",
    "y = df['cause'].astype(str)  # Convert labels to strings\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the multi-class classification model\n",
    "model = HistGradientBoostingClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bf13a-3e5d-4fad-a2d5-6073ead23609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5 Evaluating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52919ea7-c1db-4a6b-9456-fa4336eec08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "y_val_pred = model.predict_proba(X_val)\n",
    "f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "print(f'Validation F1-score: {f1:.4f}')\n",
    "\n",
    "# Tune the model's hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "y_val_pred = grid_search.predict_proba(X_val)\n",
    "f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "print(f'Tuned model validation F1-score: {f1:.4f}')\n",
    "\n",
    "# Use the tuned model for further steps\n",
    "model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064f5fb-41b2-4ec5-a5fb-0c1c076c228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 6 Prediction on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e93473-ba30-40fa-b2e3-6329c2e0e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "X_test_num = df_test[['review_length', 'sentiment_score', 'purchase_price', 'rating']]\n",
    "X_test_text = df_test['review_text']\n",
    "X_test_bert = bert_transformer.transform(df_test)\n",
    "X_test = np.hstack((X_test_num, X_test_text, X_test_bert))\n",
    "y_test_pred = model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f495ecd-04e4-4467-9a67-0e0a54500e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 7 Output Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04946fed-c7d2-40ce-aa3c-8b9d21e067b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output file\n",
    "output_df = pd.DataFrame({\n",
    "    'product_id': df_test['product_id'],\n",
    "    'order_item_id': df_test['order_item_id'],\n",
    "    'prob_return_reason_DEFECTED': y_test_pred[:, 0],\n",
    "    'prob_return_reason_WRONG_ITEM': y_test_pred[:, 1],\n",
    "    'prob_return_reason_BAD_QUALITY': y_test_pred[:, 2],\n",
    "    'prob_return_reason_PHOTO_MISMATCH': y_test_pred[:, 3],\n",
    "    'prob_return_reason_WRONG_SIZE': y_test_pred[:, 4]\n",
    "})\n",
    "\n",
    "# Save the output file in parquet format\n",
    "output_df.to_parquet('result.parquet', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
